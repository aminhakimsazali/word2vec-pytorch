{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/usr/local/lib/python3.6/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN3c106ivalue6Future15extractDataPtrsERKNS_6IValueE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b870cafa2081>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# from torchtext.data import get_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWikiText2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWikiText103\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from torchtext._torchtext import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mVocab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mVocabPybind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.6/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN3c106ivalue6Future15extractDataPtrsERKNS_6IValueE"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchtext.data import to_map_style_dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "# from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import WikiText2, WikiText103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/usr/local/lib/python3.6/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN3c106ivalue6Future15extractDataPtrsERKNS_6IValueE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-76d8f375b33a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWikiText2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWikiText103\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from torchtext._torchtext import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mVocab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mVocabPybind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.6/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN3c106ivalue6Future15extractDataPtrsERKNS_6IValueE"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchtext.data import to_map_style_dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import WikiText2, WikiText103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.constants import (\n",
    "    CBOW_N_WORDS,\n",
    "    SKIPGRAM_N_WORDS,\n",
    "    MIN_WORD_FREQUENCY,\n",
    "    MAX_SEQUENCE_LENGTH,\n",
    ")\n",
    "\n",
    "def get_english_tokenizer():\n",
    "    \"\"\"\n",
    "    Documentation:\n",
    "    https://pytorch.org/text/stable/_modules/torchtext/data/utils.html#get_tokenizer\n",
    "    \"\"\"\n",
    "    tokenizer = get_tokenizer(\"basic_english\", language=\"en\")\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def get_data_iterator(ds_name, ds_type, data_dir):\n",
    "    if ds_name == \"WikiText2\":\n",
    "        data_iter = WikiText2(root=data_dir, split=(ds_type))\n",
    "    elif ds_name == \"WikiText103\":\n",
    "        data_iter = WikiText103(root=data_dir, split=(ds_type))\n",
    "    else:\n",
    "        raise ValueError(\"Choose dataset from: WikiText2, WikiText103\")\n",
    "    data_iter = to_map_style_dataset(data_iter)\n",
    "    return data_iter\n",
    "\n",
    "\n",
    "def build_vocab(data_iter, tokenizer):\n",
    "    \"\"\"Builds vocabulary from iterator\"\"\"\n",
    "    \n",
    "    vocab = build_vocab_from_iterator(\n",
    "        map(tokenizer, data_iter),\n",
    "        specials=[\"<unk>\"],\n",
    "        min_freq=MIN_WORD_FREQUENCY,\n",
    "    )\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def collate_cbow(batch, text_pipeline):\n",
    "    \"\"\"\n",
    "    Collate_fn for CBOW model to be used with Dataloader.\n",
    "    `batch` is expected to be list of text paragrahs.\n",
    "    \n",
    "    Context is represented as N=CBOW_N_WORDS past words \n",
    "    and N=CBOW_N_WORDS future words.\n",
    "    \n",
    "    Long paragraphs will be truncated to contain\n",
    "    no more that MAX_SEQUENCE_LENGTH tokens.\n",
    "    \n",
    "    Each element in `batch_input` is N=CBOW_N_WORDS*2 context words.\n",
    "    Each element in `batch_output` is a middle word.\n",
    "    \"\"\"\n",
    "    batch_input, batch_output = [], []\n",
    "    for text in batch:\n",
    "        text_tokens_ids = text_pipeline(text)\n",
    "\n",
    "        if len(text_tokens_ids) < CBOW_N_WORDS * 2 + 1:\n",
    "            continue\n",
    "\n",
    "        if MAX_SEQUENCE_LENGTH:\n",
    "            text_tokens_ids = text_tokens_ids[:MAX_SEQUENCE_LENGTH]\n",
    "\n",
    "        for idx in range(len(text_tokens_ids) - CBOW_N_WORDS * 2):\n",
    "            token_id_sequence = text_tokens_ids[idx : (idx + CBOW_N_WORDS * 2 + 1)]\n",
    "            output = token_id_sequence.pop(CBOW_N_WORDS)\n",
    "            input_ = token_id_sequence\n",
    "            batch_input.append(input_)\n",
    "            batch_output.append(output)\n",
    "\n",
    "    batch_input = torch.tensor(batch_input, dtype=torch.long)\n",
    "    batch_output = torch.tensor(batch_output, dtype=torch.long)\n",
    "    return batch_input, batch_output\n",
    "\n",
    "\n",
    "def collate_skipgram(batch, text_pipeline):\n",
    "    \"\"\"\n",
    "    Collate_fn for Skip-Gram model to be used with Dataloader.\n",
    "    `batch` is expected to be list of text paragrahs.\n",
    "    \n",
    "    Context is represented as N=SKIPGRAM_N_WORDS past words \n",
    "    and N=SKIPGRAM_N_WORDS future words.\n",
    "    \n",
    "    Long paragraphs will be truncated to contain\n",
    "    no more that MAX_SEQUENCE_LENGTH tokens.\n",
    "    \n",
    "    Each element in `batch_input` is a middle word.\n",
    "    Each element in `batch_output` is a context word.\n",
    "    \"\"\"\n",
    "    batch_input, batch_output = [], []\n",
    "    for text in batch:\n",
    "        text_tokens_ids = text_pipeline(text)\n",
    "\n",
    "        if len(text_tokens_ids) < SKIPGRAM_N_WORDS * 2 + 1:\n",
    "            continue\n",
    "\n",
    "        if MAX_SEQUENCE_LENGTH:\n",
    "            text_tokens_ids = text_tokens_ids[:MAX_SEQUENCE_LENGTH]\n",
    "\n",
    "        for idx in range(len(text_tokens_ids) - SKIPGRAM_N_WORDS * 2):\n",
    "            token_id_sequence = text_tokens_ids[idx : (idx + SKIPGRAM_N_WORDS * 2 + 1)]\n",
    "            input_ = token_id_sequence.pop(SKIPGRAM_N_WORDS)\n",
    "            outputs = token_id_sequence\n",
    "\n",
    "            for output in outputs:\n",
    "                batch_input.append(input_)\n",
    "                batch_output.append(output)\n",
    "\n",
    "    batch_input = torch.tensor(batch_input, dtype=torch.long)\n",
    "    batch_output = torch.tensor(batch_output, dtype=torch.long)\n",
    "    return batch_input, batch_output\n",
    "\n",
    "def to_map_style_dataset(iter_data):\n",
    "    r\"\"\"Convert iterable-style dataset to map-style dataset.\n",
    "\n",
    "    args:\n",
    "        iter_data: An iterator type object. Examples include Iterable datasets, string list, text io, generators etc.\n",
    "\n",
    "\n",
    "    Examples:\n",
    "        >>> from torchtext.datasets import IMDB\n",
    "        >>> from torchtext.data import to_map_style_dataset\n",
    "        >>> train_iter = IMDB(split='train')\n",
    "        >>> train_dataset = to_map_style_dataset(train_iter)\n",
    "        >>> file_name = '.data/EnWik9/enwik9'\n",
    "        >>> data_iter = to_map_style_dataset(open(file_name,'r'))\n",
    "    \"\"\"\n",
    "\n",
    "    # Inner class to convert iterable-style to map-style dataset\n",
    "    class _MapStyleDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, iter_data):\n",
    "            # TODO Avoid list issue #1296\n",
    "            self._data = list(iter_data)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self._data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self._data[idx]\n",
    "\n",
    "    return _MapStyleDataset(iter_data)\n",
    "\n",
    "def get_dataloader_and_vocab(\n",
    "    model_name, ds_name, ds_type, data_dir, batch_size, shuffle, vocab=None\n",
    "):\n",
    "\n",
    "    data_iter = get_data_iterator(ds_name, ds_type, data_dir)\n",
    "    tokenizer = get_english_tokenizer()\n",
    "\n",
    "    if not vocab:\n",
    "        vocab = build_vocab(data_iter, tokenizer)\n",
    "        \n",
    "    text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "\n",
    "    if model_name == \"cbow\":\n",
    "        collate_fn = collate_cbow\n",
    "    elif model_name == \"skipgram\":\n",
    "        collate_fn = collate_skipgram\n",
    "    else:\n",
    "        raise ValueError(\"Choose model from: cbow, skipgram\")\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        data_iter,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=partial(collate_fn, text_pipeline=text_pipeline),\n",
    "    )\n",
    "    return dataloader, vocab\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.data import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/usr/local/lib/python3.6/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN3c106ivalue6Future15extractDataPtrsERKNS_6IValueE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-df5e62579ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dataloader_and_vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tf/data/hakim/Word-Embedding/word2vec-pytorch/utils/dataloader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# from torchtext.data import to_map_style_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# from torchtext.data import get_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from torchtext._torchtext import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mVocab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mVocabPybind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.6/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN3c106ivalue6Future15extractDataPtrsERKNS_6IValueE"
     ]
    }
   ],
   "source": [
    "from utils.dataloader import get_dataloader_and_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.trainer import Trainer\n",
    "from utils.helper import (\n",
    "    get_model_class,\n",
    "    get_optimizer_class,\n",
    "    get_lr_scheduler,\n",
    "    save_config,\n",
    "    save_vocab,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    os.makedirs(config[\"model_dir\"])\n",
    "    \n",
    "    train_dataloader, vocab = get_dataloader_and_vocab(\n",
    "        model_name=config[\"model_name\"],\n",
    "        ds_name=config[\"dataset\"],\n",
    "        ds_type=\"train\",\n",
    "        data_dir=config[\"data_dir\"],\n",
    "        batch_size=config[\"train_batch_size\"],\n",
    "        shuffle=config[\"shuffle\"],\n",
    "        vocab=None,\n",
    "    )\n",
    "\n",
    "    val_dataloader, _ = get_dataloader_and_vocab(\n",
    "        model_name=config[\"model_name\"],\n",
    "        ds_name=config[\"dataset\"],\n",
    "        ds_type=\"valid\",\n",
    "        data_dir=config[\"data_dir\"],\n",
    "        batch_size=config[\"val_batch_size\"],\n",
    "        shuffle=config[\"shuffle\"],\n",
    "        vocab=vocab,\n",
    "    )\n",
    "\n",
    "    vocab_size = len(vocab.get_stoi())\n",
    "    print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "    model_class = get_model_class(config[\"model_name\"])\n",
    "    model = model_class(vocab_size=vocab_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_class = get_optimizer_class(config[\"optimizer\"])\n",
    "    optimizer = optimizer_class(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    lr_scheduler = get_lr_scheduler(optimizer, config[\"epochs\"], verbose=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        epochs=config[\"epochs\"],\n",
    "        train_dataloader=train_dataloader,\n",
    "        train_steps=config[\"train_steps\"],\n",
    "        val_dataloader=val_dataloader,\n",
    "        val_steps=config[\"val_steps\"],\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        checkpoint_frequency=config[\"checkpoint_frequency\"],\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        device=device,\n",
    "        model_dir=config[\"model_dir\"],\n",
    "        model_name=config[\"model_name\"],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "    trainer.save_model()\n",
    "    trainer.save_loss()\n",
    "    save_vocab(vocab, config[\"model_dir\"])\n",
    "    save_config(config, config[\"model_dir\"])\n",
    "    print(\"Model artifacts saved to folder:\", config[\"model_dir\"])\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--config', type=str, required=True, help='path to yaml config')\n",
    "    args = parser.parse_args()\n",
    "    print(\"Arg : \", args)\n",
    "    \n",
    "    with open(args.config, 'r') as stream:\n",
    "        config = yaml.safe_load(stream)\n",
    "    train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
