{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85bfff64",
   "metadata": {},
   "source": [
    "# Build DataLoader for Malaysia Kini data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d4d2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ba6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils.dataloader import get_dataloader_and_vocab\n",
    "from utils.trainer import Trainer\n",
    "from utils.helper import (\n",
    "    get_model_class,\n",
    "    get_optimizer_class,\n",
    "    get_lr_scheduler,\n",
    "    save_config,\n",
    "    save_vocab,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30c24e",
   "metadata": {},
   "source": [
    "## 1: Configuration File & Delete existing folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3209f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'model_name': 'skipgram',\n",
    "#  'dataset': 'WikiText2',\n",
    "#  'data_dir': 'data/',\n",
    " 'train_batch_size': 96,\n",
    " 'val_batch_size': 96,\n",
    " 'shuffle': True,\n",
    " 'optimizer': 'Adam',\n",
    " 'learning_rate': 0.025,\n",
    " 'epochs': 5,\n",
    " 'train_steps': None,\n",
    " 'val_steps': None,\n",
    " 'checkpoint_frequency': None,\n",
    " 'model_dir': 'weights/skipgram_MalaysiaKini'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96470bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists(config['model_dir']):\n",
    "#     os.removedirs(config['model_dir'])\n",
    "    shutil.rmtree(config['model_dir'])\n",
    "\n",
    "#Create model directory\n",
    "os.makedirs(config[\"model_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86470000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def to_map_style_dataset(iter_data):\n",
    "    r\"\"\"Convert iterable-style dataset to map-style dataset.\n",
    "\n",
    "    args:\n",
    "        iter_data: An iterator type object. Examples include Iterable datasets, string list, text io, generators etc.\n",
    "\n",
    "\n",
    "    Examples:\n",
    "        >>> from torchtext.datasets import IMDB\n",
    "        >>> from torchtext.data import to_map_style_dataset\n",
    "        >>> train_iter = IMDB(split='train')\n",
    "        >>> train_dataset = to_map_style_dataset(train_iter)\n",
    "        >>> file_name = '.data/EnWik9/enwik9'\n",
    "        >>> data_iter = to_map_style_dataset(open(file_name,'r'))\n",
    "    \"\"\"\n",
    "\n",
    "    # Inner class to convert iterable-style to map-style dataset\n",
    "    class _MapStyleDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, iter_data):\n",
    "            # TODO Avoid list issue #1296\n",
    "#             self._data = list(iter_data)\n",
    "            self._data =  iter_data\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self._data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self._data[idx]\n",
    "\n",
    "    return _MapStyleDataset(iter_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17864a44",
   "metadata": {},
   "source": [
    "## 2: Read data and create DataLoader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7224be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MalaysiaKiniData(Dataset):\n",
    "    def __init__(self, data):\n",
    "        #load data\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #return exact data\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        #return data length\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73d06019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import collate_skipgram, collate_cbow, build_vocab\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import pandas as pd\n",
    "\n",
    "def get_dataloader_and_vocab_malay(\n",
    "    model_name, ds_path, ds_column, batch_size, shuffle, vocab=None\n",
    "):\n",
    "\n",
    "    df = pd.read_csv(ds_path)\n",
    "    df = df.dropna(how=\"any\")\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "    def yield_sentences():\n",
    "        for sent in df[ds_column]:\n",
    "            yield sent\n",
    "\n",
    "    sentences_generator = yield_sentences()\n",
    "\n",
    "    data_iter = MalaysiaKiniData(df[ds_column])\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "    \n",
    "    if not vocab:\n",
    "        vocab = build_vocab(sentences_generator, tokenizer)\n",
    "        \n",
    "    text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "\n",
    "    if model_name == \"cbow\":\n",
    "        collate_fn = collate_cbow\n",
    "    elif model_name == \"skipgram\":\n",
    "        collate_fn = collate_skipgram\n",
    "    else:\n",
    "        raise ValueError(\"Choose model from: cbow, skipgram\")\n",
    "    print(\"Vocab size: \", len(vocab.get_stoi()))\n",
    "    dataloader = DataLoader(\n",
    "        data_iter,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=partial(collate_fn, text_pipeline=text_pipeline),\n",
    "    )\n",
    "    return dataloader, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ff5ba1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  1715\n",
      "Vocabulary size: 1715\n"
     ]
    }
   ],
   "source": [
    "#Load train dataset\n",
    "\n",
    "train_dataloader, vocab = get_dataloader_and_vocab_malay(\n",
    "    model_name=config[\"model_name\"],\n",
    "    ds_path = \"data/malaysia-kini/train.csv\",\n",
    "    ds_column = \"Target\",\n",
    "    batch_size=config[\"train_batch_size\"],\n",
    "#     shuffle=config[\"shuffle\"],\n",
    "    shuffle=False,\n",
    "    vocab=None,\n",
    ")\n",
    "\n",
    "#Get vocab size\n",
    "vocab_size = len(vocab.get_stoi())\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f421fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  380\n"
     ]
    }
   ],
   "source": [
    "#Load Validation dataset\n",
    "val_dataloader, _ = get_dataloader_and_vocab_malay(\n",
    "    model_name=config[\"model_name\"],\n",
    "    ds_path = \"data/malaysia-kini/valid.csv\",\n",
    "    ds_column = \"Target\",\n",
    "    batch_size=config[\"train_batch_size\"],\n",
    "#     shuffle=config[\"shuffle\"],\n",
    "    shuffle=False,\n",
    "    vocab=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "713e27a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1715\n",
      "Adjusting learning rate of group 0 to 2.5000e-02.\n"
     ]
    }
   ],
   "source": [
    "#Get vocab size\n",
    "vocab_size = len(vocab.get_stoi())\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "#Get model config\n",
    "model_class = get_model_class(config[\"model_name\"])\n",
    "model = model_class(vocab_size=vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Model parameters : optimizer, learning rate\n",
    "optimizer_class = get_optimizer_class(config[\"optimizer\"])\n",
    "optimizer = optimizer_class(model.parameters(), lr=config[\"learning_rate\"])\n",
    "lr_scheduler = get_lr_scheduler(optimizer, config[\"epochs\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7090b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set training on CUDA if CUDA available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01b0a761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Train Loss=5.47417, Val Loss=4.04396\n",
      "Adjusting learning rate of group 0 to 2.0000e-02.\n",
      "Epoch: 2/5, Train Loss=5.32944, Val Loss=4.00713\n",
      "Adjusting learning rate of group 0 to 1.5000e-02.\n",
      "Epoch: 3/5, Train Loss=5.28547, Val Loss=3.98888\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 4/5, Train Loss=5.25762, Val Loss=3.97517\n",
      "Adjusting learning rate of group 0 to 5.0000e-03.\n",
      "Epoch: 5/5, Train Loss=5.22800, Val Loss=3.96532\n",
      "Adjusting learning rate of group 0 to 0.0000e+00.\n",
      "Training finished.\n",
      "Model artifacts saved to folder: weights/skipgram_MalaysiaKini\n"
     ]
    }
   ],
   "source": [
    "#Model training\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    epochs=config[\"epochs\"],\n",
    "    train_dataloader=train_dataloader,\n",
    "    train_steps=config[\"train_steps\"],\n",
    "    val_dataloader=val_dataloader,\n",
    "    val_steps=config[\"val_steps\"],\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    checkpoint_frequency=config[\"checkpoint_frequency\"],\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    device=device,\n",
    "    model_dir=config[\"model_dir\"],\n",
    "    model_name=config[\"model_name\"],\n",
    ")\n",
    "\n",
    "#Finish training\n",
    "trainer.train()\n",
    "print(\"Training finished.\")\n",
    "\n",
    "trainer.save_model()\n",
    "trainer.save_loss()\n",
    "save_vocab(vocab, config[\"model_dir\"])\n",
    "save_config(config, config[\"model_dir\"])\n",
    "print(\"Model artifacts saved to folder:\", config[\"model_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8db8452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e67a52a5",
   "metadata": {},
   "source": [
    "## Read data all Malaysia Kini data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a9475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e10a19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/malaysia-kini/06_MalaysiaKini & Awani Articles 2022.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fee15b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116030 entries, 0 to 116029\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Target       116030 non-null  object\n",
      " 1   Source       116030 non-null  object\n",
      " 2   Text Length  116030 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13ecc2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = df['Target'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adabbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.extend( df['Source'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4b3f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSeries = pd.Series(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c098864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSeries.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea70992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSeries.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08a0324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSeries.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f37f98ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         global | kumpulan hak asasi manusia dan duta u...\n",
       "1         amnesty international dan human rights watch b...\n",
       "2         duta ukraine ke amerika syarikat, oksana marka...\n",
       "3         \"mereka menggunakan bom vakum hari ini,\" kata ...\n",
       "4         \"...kemusnahan yang cuba dikenakan oleh rusia ...\n",
       "                                ...                        \n",
       "220321    beliau berkata para pelabur menantikan dengan ...\n",
       "220322    \"ringgit dijangka diniagakan tggi dn menguji p...\n",
       "220323    berbanding mata wang utama yg lain, ringgit be...\n",
       "220324    unit tempatan tue lebih tnggi berbanding dolar...\n",
       "220325    bagaimanapun, ringgit lemah berbanding yen jep...\n",
       "Length: 220326, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd5f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55494370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
